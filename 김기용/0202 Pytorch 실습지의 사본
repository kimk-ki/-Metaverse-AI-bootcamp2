{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"nzpMkmJCt0G1"},"source":["## Pytorch\n","### 1. 라이브러리 불러오기\n","\n","파이토치 라이브러리를 불러오고, 다양한 하위 모듈을 불러옵니다. \n","\n","* nn: 그래프 만드는 클래스 \n","* Dataset: 데이터셋 만들기 \n","* DataLoader: 데이터셋에서 데이터를 불러와 반복 연산하기 \n","* F: torch.nn 클래스 안에 있는 유용하게 사용할 수 있는 함수 \n","\n","jupyter notebook 이 아닌 환경이라면 다음의 링크를 확인해보세요.\n","\n","https://pytorch.org/get-started/locally/#start-locally  "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"f-16PT_Tp3h5","executionInfo":{"status":"ok","timestamp":1675322826031,"user_tz":-540,"elapsed":567,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"outputs":[],"source":["import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","metadata":{"id":"VzWdI2ZBlT4z"},"source":["### 2. 데이터 작업하기 \n","\n","2-1. 데이터셋 만들기 \n","\n","데이터를 담을 Dataset 클래스를 생성합니다. 여기에는 세 개의 함수가 꼭 필요합니다. \n","* `__init__` : 파일을 불러오고 결측값을 처리합니다. 각각의 열을 tensor 로 불러옵니다. \n","* `__getitem__` : index 로 각 행을 호출합니다. \n","* `__len__`: 전체 길이를 불러옵니다. "]},{"cell_type":"code","execution_count":2,"metadata":{"id":"pv65wUvwqGaP","executionInfo":{"status":"ok","timestamp":1675322828912,"user_tz":-540,"elapsed":697,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"outputs":[],"source":["import pandas as pd \n","\n","class EnergyDataset(Dataset):\n","  \n","  # 데이터 담을 객체 생성하기 \n","  def __init__(self, file_name):\n","\n","    # 파일 불러오기 \n","    file_out = pd.read_csv(file_name)\n","\n","    # 하나라도 결측값이 있는 행 모두 제거하기 \n","    # 결측값이 있는 경우 결과에 nan 값이 나오니 모두 제거해줍니다. \n","    file_out = file_out.dropna(how='any')\n","    \n","    self.nuclear = torch.from_numpy(file_out['nuclear_consumption'].values).unsqueeze(dim=1).float()\n","    #self.oil = torch.from_numpy(file_out['oil_consumption'].values).unsqueeze(dim=1).float()\n","    self.population = torch.from_numpy(file_out['population'].values).unsqueeze(dim=1).float()\n","    #self.gdp = torch.from_numpy(file_out['gdp'].values).unsqueeze(dim=1).float()\n","\n","    self.min_x, self.max_x, self.population = self.normalization(self.population)\n","    self.min_y, self.max_y, self.nuclear = self.normalization(self.nuclear) \n","\n","  # x, y 값 Normalization 함수. 데이터의 범위를 0~1로 변환시켜주는 함수.\n","  def normalization(self, data, min=False, max=False):\n","    if max:\n","      max, min = max, min\n","    else:\n","      max = torch.max(data)\n","      min = torch.min(data)\n","    norm_data = (data-min) / (max - min)\n","    return min, max, norm_data \n","\n","  # x, y 값 Denormalization 함수. 0~1로 바뀐 함수를 본래 값의 범위로 변환하는 함수.\n","  def denormalization(self, min, max, norm_data):\n","    data = norm_data*(max - min) + min\n","    return data\n","\n","  # 인덱스에 대한 데이터를 반환하기 \n","  def __getitem__(self, index):\n","    nuclear = self.nuclear[index]\n","    #oil = self.oil[index]\n","    population = self.population[index]\n","    #gdp = self.gdp[index]\n","\n","    return nuclear, population\n","    # oil, gdp\n","\n","  # 학습할 데이터의 총 개수 반환하기  \n","  def __len__(self):\n","    return len(self.population) "]},{"cell_type":"markdown","metadata":{"id":"VSkUTnOAr6Ri"},"source":["2-2. 데이터 불러오기 \n","\n","파일명을 넣어 데이터를 불러옵니다. 첫번째 행과 마지막 행을 출력해보아 데이터를 확인합니다. "]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xhabPTuJLRo","outputId":"be4e0768-c5cc-42ee-b84e-c7a6cfb0fc28","executionInfo":{"status":"ok","timestamp":1675322831158,"user_tz":-540,"elapsed":4,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([0.]), tensor([0.]))\n","(tensor([0.9774]), tensor([1.]))\n"]}],"source":["energy_data = EnergyDataset('korea_energy_data.csv')\n","\n","print(energy_data[0])\n","print(energy_data[-1])"]},{"cell_type":"markdown","metadata":{"id":"Vs4DNrYCssRC"},"source":["### 3. 모델 생성하기 \n","\n","3-1. 선형 회귀 모델 "]},{"cell_type":"code","source":["# x, y 값 설정하기 \n","x = energy_data.population\n","y = energy_data.nuclear"],"metadata":{"id":"0YVnu6f7Iy_k","executionInfo":{"status":"ok","timestamp":1675322649158,"user_tz":-540,"elapsed":602,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# 모델 정의하기 \n","torch.manual_seed(1)\n","\n","model = nn.Linear(1, 1)\n","optimizer = torch.optim.SGD(model.parameters(), lr = 1e-2)"],"metadata":{"id":"_8kAJDg2K9wM","executionInfo":{"status":"ok","timestamp":1675322651445,"user_tz":-540,"elapsed":2,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0Ym8vO1e6bo","outputId":"11f1d4ce-4769-4893-d4a5-48950030eb17","executionInfo":{"status":"ok","timestamp":1675322654646,"user_tz":-540,"elapsed":750,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/4000 Cost: 0.487868\n","Epoch  200/4000 Cost: 0.010702\n","Epoch  400/4000 Cost: 0.008327\n","Epoch  600/4000 Cost: 0.006932\n","Epoch  800/4000 Cost: 0.006110\n","Epoch 1000/4000 Cost: 0.005626\n","Epoch 1200/4000 Cost: 0.005341\n","Epoch 1400/4000 Cost: 0.005174\n","Epoch 1600/4000 Cost: 0.005075\n","Epoch 1800/4000 Cost: 0.005017\n","Epoch 2000/4000 Cost: 0.004982\n","Epoch 2200/4000 Cost: 0.004962\n","Epoch 2400/4000 Cost: 0.004950\n","Epoch 2600/4000 Cost: 0.004943\n","Epoch 2800/4000 Cost: 0.004939\n","Epoch 3000/4000 Cost: 0.004937\n","Epoch 3200/4000 Cost: 0.004935\n","Epoch 3400/4000 Cost: 0.004934\n","Epoch 3600/4000 Cost: 0.004934\n","Epoch 3800/4000 Cost: 0.004934\n","Epoch 4000/4000 Cost: 0.004933\n"]}],"source":["# 모델 학습시키기 \n","nb_epochs = 4000\n","for epoch in range(nb_epochs+1):\n","\n","  prediction = model(x)\n","\n","  cost = F.mse_loss(prediction, y)\n","\n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","\n","  if epoch % 200 == 0:\n","    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, cost.item()\n","    ))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gx5pO5Gpf9ds","outputId":"85fcbd95-8b9c-46c8-b8fc-4e30025efb91","executionInfo":{"status":"ok","timestamp":1675322656611,"user_tz":-540,"elapsed":3,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[Parameter containing:\n","tensor([[1.1525]], requires_grad=True), Parameter containing:\n","tensor([-0.1508], requires_grad=True)]\n"]}],"source":["print(list(model.parameters()))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upXN40M3fz66","outputId":"5c509eca-98b4-4bf6-ea24-f1f17f4c7bce","executionInfo":{"status":"ok","timestamp":1675322658982,"user_tz":-540,"elapsed":3,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 후 입력이 49000000.0일 때의 예측값 : tensor(351.8950)\n","훈련 후 입력이 50000000.0일 때의 예측값 : tensor(384.9907)\n"]}],"source":["# 새로운 값에 대해 확인해보기 \n","test_value = 49000000.0\n","norm_test = energy_data.normalization(test_value, energy_data.min_x, energy_data.max_x)[2]\n","new_var = torch.FloatTensor([[norm_test]]) \n","pred_y = model(new_var).item()\n","print(f\"훈련 후 입력이 {test_value}일 때의 예측값 :\", energy_data.denormalization(energy_data.min_y, energy_data.max_y, pred_y)) \n","\n","test_value = 50000000.0\n","norm_test = energy_data.normalization(test_value, energy_data.min_x, energy_data.max_x)[2]\n","new_var = torch.FloatTensor([[norm_test]]) \n","pred_y = model(new_var).item()\n","print(f\"훈련 후 입력이 {test_value}일 때의 예측값 :\", energy_data.denormalization(energy_data.min_y, energy_data.max_y, pred_y)) "]},{"cell_type":"markdown","metadata":{"id":"5IPR-R48vJz5"},"source":["3-2. 신경망 모델 "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"owkYz4DH2oQ_","outputId":"6fa5025a-a55f-4dea-c6e8-b3ebef6b2000","executionInfo":{"status":"ok","timestamp":1675322840111,"user_tz":-540,"elapsed":4028,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n","NeuralNetwork(\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=1, out_features=100, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=100, out_features=100, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=100, out_features=1, bias=True)\n","    (5): Sigmoid()\n","  )\n",")\n"]}],"source":["# cpu나 gpu 장치 얻기 \n","device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n","print(f\"Using {device} device\")\n","\n","# 모델 정의하기 \n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(1, 100),\n","            nn.ReLU(),\n","            nn.Linear(100, 100),\n","            nn.ReLU(),\n","            nn.Linear(100, 1),\n","            nn.Sigmoid()\n","            )\n","\n","    def forward(self, x):\n","        out = self.linear_relu_stack(x)\n","        return out\n","\n","model = NeuralNetwork().to(device)\n","print(model)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"PKDjHSTd2vXw","executionInfo":{"status":"ok","timestamp":1675322842667,"user_tz":-540,"elapsed":2,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"outputs":[],"source":["# 모델 매개변수 최적화하기 \n","loss_fn = nn.MSELoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"H2AKHtv72xSd","executionInfo":{"status":"ok","timestamp":1675322845276,"user_tz":-540,"elapsed":3,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"outputs":[],"source":["def train(dataloader, model, loss_fn, optimizer, ep):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    total_loss = 0\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        # 1) 예측 오류 계산 \n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # 2) 역전파\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","    if (ep+1)%100==0:\n","      print(f\"Epoch {ep+1}\\n-------------------------------\")\n","      total_loss /= (batch+1)\n","      print(f\"Train loss: {total_loss:>7f}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"rBZIG0NNxFwr","executionInfo":{"status":"ok","timestamp":1675322847230,"user_tz":-540,"elapsed":3,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"outputs":[],"source":["def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss = 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","    test_loss /= num_batches\n","    print(f\"Test loss: {test_loss:>8f} \\n\")"]},{"cell_type":"markdown","source":["#### 원칙적으로 train과 test 데이터는 달라야하지만, 현재는 train과 test의 저체 흐름에 초점을 맞추기 위해서 데이터셋을 동일하게 하였습니다."],"metadata":{"id":"23JKqSqUsjDI"}},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AgFab7nH21Mz","outputId":"f192fdef-228a-4cf2-aad1-8819f8e93c39","executionInfo":{"status":"ok","timestamp":1675322855954,"user_tz":-540,"elapsed":6305,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 100\n","-------------------------------\n","Train loss: 0.074902\n","Test loss: 0.074773 \n","\n","Epoch 200\n","-------------------------------\n","Train loss: 0.065368\n","Test loss: 0.065296 \n","\n","Epoch 300\n","-------------------------------\n","Train loss: 0.058575\n","Test loss: 0.058508 \n","\n","Epoch 400\n","-------------------------------\n","Train loss: 0.051883\n","Test loss: 0.051816 \n","\n","Epoch 500\n","-------------------------------\n","Train loss: 0.045224\n","Test loss: 0.045157 \n","\n","Epoch 600\n","-------------------------------\n","Train loss: 0.038714\n","Test loss: 0.038650 \n","\n","Epoch 700\n","-------------------------------\n","Train loss: 0.032566\n","Test loss: 0.032507 \n","\n","Epoch 800\n","-------------------------------\n","Train loss: 0.027009\n","Test loss: 0.026957 \n","\n","Epoch 900\n","-------------------------------\n","Train loss: 0.022220\n","Test loss: 0.022176 \n","\n","Epoch 1000\n","-------------------------------\n","Train loss: 0.018237\n","Test loss: 0.018201 \n","\n","Epoch 1100\n","-------------------------------\n","Train loss: 0.015020\n","Test loss: 0.014992 \n","\n","Epoch 1200\n","-------------------------------\n","Train loss: 0.012482\n","Test loss: 0.012460 \n","\n","Epoch 1300\n","-------------------------------\n","Train loss: 0.010516\n","Test loss: 0.010499 \n","\n","Epoch 1400\n","-------------------------------\n","Train loss: 0.009008\n","Test loss: 0.008995 \n","\n","Epoch 1500\n","-------------------------------\n","Train loss: 0.007871\n","Test loss: 0.007862 \n","\n","Epoch 1600\n","-------------------------------\n","Train loss: 0.007002\n","Test loss: 0.006995 \n","\n","Epoch 1700\n","-------------------------------\n","Train loss: 0.006335\n","Test loss: 0.006329 \n","\n","Epoch 1800\n","-------------------------------\n","Train loss: 0.005819\n","Test loss: 0.005815 \n","\n","Epoch 1900\n","-------------------------------\n","Train loss: 0.005420\n","Test loss: 0.005417 \n","\n","Epoch 2000\n","-------------------------------\n","Train loss: 0.005108\n","Test loss: 0.005106 \n","\n","Epoch 2100\n","-------------------------------\n","Train loss: 0.004863\n","Test loss: 0.004861 \n","\n","Epoch 2200\n","-------------------------------\n","Train loss: 0.004669\n","Test loss: 0.004667 \n","\n","Epoch 2300\n","-------------------------------\n","Train loss: 0.004514\n","Test loss: 0.004512 \n","\n","Epoch 2400\n","-------------------------------\n","Train loss: 0.004389\n","Test loss: 0.004388 \n","\n","Epoch 2500\n","-------------------------------\n","Train loss: 0.004288\n","Test loss: 0.004287 \n","\n","Epoch 2600\n","-------------------------------\n","Train loss: 0.004205\n","Test loss: 0.004204 \n","\n","Epoch 2700\n","-------------------------------\n","Train loss: 0.004138\n","Test loss: 0.004138 \n","\n","Epoch 2800\n","-------------------------------\n","Train loss: 0.004083\n","Test loss: 0.004083 \n","\n","Epoch 2900\n","-------------------------------\n","Train loss: 0.004038\n","Test loss: 0.004038 \n","\n","Epoch 3000\n","-------------------------------\n","Train loss: 0.004001\n","Test loss: 0.004000 \n","\n","Epoch 3100\n","-------------------------------\n","Train loss: 0.003969\n","Test loss: 0.003968 \n","\n","Epoch 3200\n","-------------------------------\n","Train loss: 0.003942\n","Test loss: 0.003941 \n","\n","Epoch 3300\n","-------------------------------\n","Train loss: 0.003918\n","Test loss: 0.003918 \n","\n","Epoch 3400\n","-------------------------------\n","Train loss: 0.003898\n","Test loss: 0.003898 \n","\n","Epoch 3500\n","-------------------------------\n","Train loss: 0.003880\n","Test loss: 0.003880 \n","\n","Epoch 3600\n","-------------------------------\n","Train loss: 0.003864\n","Test loss: 0.003864 \n","\n","Epoch 3700\n","-------------------------------\n","Train loss: 0.003850\n","Test loss: 0.003850 \n","\n","Epoch 3800\n","-------------------------------\n","Train loss: 0.003838\n","Test loss: 0.003838 \n","\n","Epoch 3900\n","-------------------------------\n","Train loss: 0.003826\n","Test loss: 0.003826 \n","\n","Epoch 4000\n","-------------------------------\n","Train loss: 0.003815\n","Test loss: 0.003815 \n","\n","Done!\n"]}],"source":["train_dataloader = DataLoader(energy_data, batch_size=512, shuffle=True)\n","\n","epochs = 4000\n","for ep in range(epochs):\n","    train(train_dataloader, model, loss_fn, optimizer, ep)\n","    if (ep+1)%100==0:\n","      test(train_dataloader, model, loss_fn)\n","print(\"Done!\")"]},{"cell_type":"code","source":["# 새로운 값에 대해 확인해보기 \n","test_value = 49000000.0\n","norm_test = energy_data.normalization(test_value, energy_data.min_x, energy_data.max_x)[2]\n","new_var = torch.FloatTensor([[norm_test]]) \n","pred_y = model(new_var).item()\n","print(f\"훈련 후 입력이 {test_value}일 때의 예측값 :\", energy_data.denormalization(energy_data.min_y, energy_data.max_y, pred_y)) \n","\n","test_value = 50000000.0\n","norm_test = energy_data.normalization(test_value, energy_data.min_x, energy_data.max_x)[2]\n","new_var = torch.FloatTensor([[norm_test]]) \n","pred_y = model(new_var).item()\n","print(f\"훈련 후 입력이 {test_value}일 때의 예측값 :\", energy_data.denormalization(energy_data.min_y, energy_data.max_y, pred_y)) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"id":"weLXvm3inKri","outputId":"691e1a9c-b1bf-419b-8f47-93e931f530e6","executionInfo":{"status":"error","timestamp":1675322859888,"user_tz":-540,"elapsed":5,"user":{"displayName":"ki kim","userId":"11877903355283430795"}}},"execution_count":9,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-7e0d14dc59fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnorm_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menergy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnorm_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"훈련 후 입력이 {test_value}일 때의 예측값 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-c0b1c9d40474>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_relu_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NQ8qPvrkA-q_"},"execution_count":null,"outputs":[]}]}